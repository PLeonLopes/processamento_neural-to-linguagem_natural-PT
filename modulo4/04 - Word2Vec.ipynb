{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zljehcW10P5q"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/imagens/logo_nlportugues.png\"   width=\"150\" align=\"right\">\n",
    "\n",
    "# Lista 4 - Word2Vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bUareHn6UqM"
   },
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw8FPTMX0P5s"
   },
   "source": [
    "Nessa lista nós exploraremos o espaço vetorial gerado pelo algoritmo Word2Vec e algumas de suas propriedades mais interessantes. Veremos como palavras similares se organizam nesse espaço e as relações de palavras com seus sinônimos e antônimos. Também veremos algumas analogias interessantes que o algoritmo é capaz de fazer ao capturar um pouco do nosso uso da língua portuguesa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1005,
     "status": "ok",
     "timestamp": 1652789427145,
     "user": {
      "displayName": "Alan Barzilay",
      "userId": "11025662713341670302"
     },
     "user_tz": -120
    },
    "id": "vR52KVnq0P5t"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KUL7X3F0P5u"
   },
   "source": [
    "# Carregando dados\n",
    "\n",
    "\n",
    "Para esta lista nós utilizaremos vetores de palavras, também conhecidos como *embeddings*, para lingua portuguesa fornecidos pelo [NILC](http://www.nilc.icmc.usp.br/nilc/index.php). Nós utilizaremos o embedding de 50 dimensões treinado com o algoritmo Word2Vec (Continous Bag of Words) que pode ser encontrado [aqui](http://www.nilc.icmc.usp.br/embeddings) sob a licensa [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Para evitar problemas de mémoria utilizaremos apenas as 200 mil palavras mais comum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sEwqxBvD0Rga"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  1 92.0M    1 1424k    0     0  1304k      0  0:01:12  0:00:01  0:01:11 1308k\n",
      " 47 92.0M   47 44.0M    0     0  21.0M      0  0:00:04  0:00:02  0:00:02 21.0M\n",
      "100 92.0M  100 92.0M    0     0  33.1M      0  0:00:02  0:00:02 --:--:-- 33.2M\n"
     ]
    }
   ],
   "source": [
    "!curl  https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/Semana%2004/data/word2vec_200k.txt --output 'word2vec_200k.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Bwajr5sQ0P5v"
   },
   "outputs": [],
   "source": [
    "# Carrega word2vec\n",
    "model = KeyedVectors.load_word2vec_format(\"word2vec_200k.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2JYtS1k0P5v"
   },
   "source": [
    "# Similaridade e Distância Cosseno \n",
    "\n",
    "Como comentamos em sala de aula, podemos considerar as palavras como pontos num espaço n-dimensional e podemos examinar a proximidade delas através da similaridade cosseno:\n",
    "$$s = \\frac{u \\cdot v}{||u|| ||v||}, \\textrm{ onde } s \\in [-1, 1] $$ \n",
    "\n",
    "\n",
    "## <font color='blue'>Questão 1 </font>\n",
    "Palavras [polissemicas](https://pt.wikipedia.org/wiki/Polissemia) e [homônimas](https://pt.wikipedia.org/wiki/Hom%C3%B3nimo) são palavras que possuem mais de um significado. \n",
    "\n",
    "\n",
    "Utilizando a função `model.most_similar(positive = palavra1)`, que retorna uma lista das palavras mais similares à palavra1, encontre uma palavra que possua múltiplos significados. Observe que na sua lista de 10 palavras mais similares existam palavras relacionadas a mais de um dos seus significados, lembre-se de consultar sua [documentação](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar). \n",
    "\n",
    "Por exemplo, a palavra \"manga\" possui na sua lista de 10 palavras mais similares as palavras \"gola\" e \"lapela\" (que estão relacionadas ao significado de manga de uma camiseta) e a palavra \"maçã\" (que está relacionada ao significado da fruta manga).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qbvAUIa30P5w"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lapela', 0.7861751914024353),\n",
       " ('gola', 0.7740796804428101),\n",
       " ('cola', 0.7732387781143188),\n",
       " ('maça', 0.7641578912734985),\n",
       " ('serapilheira', 0.7618493437767029),\n",
       " ('aréola', 0.7610149383544922),\n",
       " ('cachaça', 0.7603256702423096),\n",
       " ('pantera', 0.7558174729347229),\n",
       " ('cuia', 0.7498409748077393),\n",
       " ('canela', 0.741802990436554)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (codigo completo em (modulo4/q1.py))\n",
    "# EXEMPLO FEITO COM A PALAVRA MANGA\n",
    "\n",
    "model.most_similar(positive = \"manga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('maçã', 0.9109430313110352),\n",
       " ('sombrinha', 0.8988646864891052),\n",
       " ('máscara', 0.8968290686607361),\n",
       " ('argola', 0.8952800631523132),\n",
       " ('chupeta', 0.8921788334846497),\n",
       " ('mortalha', 0.8916767835617065),\n",
       " ('cabaça', 0.8912543654441833),\n",
       " ('cuia', 0.8907310366630554),\n",
       " ('estola', 0.8845382928848267),\n",
       " ('espada', 0.8800477981567383)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (codigo completo em (modulo4/q1.py))\n",
    "# EXEMPLO FEITO COM A PALAVRA MAÇA\n",
    "\n",
    "model.most_similar(positive = \"maça\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6YKYZ_z0P5x"
   },
   "source": [
    "# Sinônimos e Antônimos\n",
    "\n",
    "\n",
    "As vezes é mais intuitivo trabalhar com uma medida de distancia ao invés da similaridade cosseno, para isso vamos utilizar a distancia cosseno que é simplesmente 1 - Similaridade Cosseno.\n",
    "\n",
    "## <font color='blue'>Questão 2 </font>\n",
    "\n",
    "\n",
    "Usando a função [`model.distance(palavra1,palavra2)`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance), encontre 3 palavras onde as palavras p1 e p2 são sinônimas e p1 e p3 são antônimas mas `distance(p1,p3)` < `distance(p1,p2)`.\n",
    "\n",
    "Proponha uma explicação do porque esse resultado contraintuitivo acontece.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JeywFdKk0P5y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analisando a palavra: manga\n",
      "Palavras similares a 'manga': ['lapela', 'gola', 'cola', 'maça', 'serapilheira', 'aréola', 'cachaça', 'pantera', 'cuia', 'canela']\n",
      "Distância entre 'manga' e 'lapela': 0.21382474899291992\n",
      "Distância entre 'manga' e 'gola': 0.2259204387664795\n",
      "Distância entre 'manga' e 'lapela': 0.21382474899291992\n",
      "Distância entre 'manga' e 'cola': 0.22676128149032593\n",
      "Distância entre 'manga' e 'lapela': 0.21382474899291992\n",
      "Distância entre 'manga' e 'maça': 0.23584216833114624\n",
      "Distância entre 'manga' e 'lapela': 0.21382474899291992\n",
      "Distância entre 'manga' e 'serapilheira': 0.23815059661865234\n",
      "Distância entre 'manga' e 'lapela': 0.21382474899291992\n",
      "Distância entre 'manga' e 'aréola': 0.2389851212501526\n",
      "Distância entre 'manga' e 'lapela': 0.21382474899291992\n",
      "Distância entre 'manga' e 'cachaça': 0.23967427015304565\n",
      "Distância entre 'manga' e 'lapela': 0.21382474899291992\n",
      "Distância entre 'manga' e 'pantera': 0.24418246746063232\n",
      "Distância entre 'manga' e 'lapela': 0.21382474899291992\n",
      "Distância entre 'manga' e 'cuia': 0.2501590847969055\n",
      "Distância entre 'manga' e 'lapela': 0.21382474899291992\n",
      "Distância entre 'manga' e 'canela': 0.2581970691680908\n",
      "\n",
      "Analisando a palavra: maça\n",
      "Palavras similares a 'maça': ['maçã', 'sombrinha', 'máscara', 'argola', 'chupeta', 'mortalha', 'cabaça', 'cuia', 'estola', 'espada']\n",
      "Distância entre 'maça' e 'maçã': 0.08905696868896484\n",
      "Distância entre 'maça' e 'sombrinha': 0.10113525390625\n",
      "Distância entre 'maça' e 'maçã': 0.08905696868896484\n",
      "Distância entre 'maça' e 'máscara': 0.10317087173461914\n",
      "Distância entre 'maça' e 'maçã': 0.08905696868896484\n",
      "Distância entre 'maça' e 'argola': 0.10471993684768677\n",
      "Distância entre 'maça' e 'maçã': 0.08905696868896484\n",
      "Distância entre 'maça' e 'chupeta': 0.10782104730606079\n",
      "Distância entre 'maça' e 'maçã': 0.08905696868896484\n",
      "Distância entre 'maça' e 'mortalha': 0.10832321643829346\n",
      "Distância entre 'maça' e 'maçã': 0.08905696868896484\n",
      "Distância entre 'maça' e 'cabaça': 0.10874563455581665\n",
      "Distância entre 'maça' e 'maçã': 0.08905696868896484\n",
      "Distância entre 'maça' e 'cuia': 0.10926902294158936\n",
      "Distância entre 'maça' e 'maçã': 0.08905696868896484\n",
      "Distância entre 'maça' e 'estola': 0.11546176671981812\n",
      "Distância entre 'maça' e 'maçã': 0.08905696868896484\n",
      "Distância entre 'maça' e 'espada': 0.1199522614479065\n",
      "\n",
      "Analisando a palavra: feliz\n",
      "Palavras similares a 'feliz': ['feiiz', 'triste', 'contente', 'aliviada', 'lisonjeada', 'excitada', 'deprimido', 'agradecida', 'envergonhada', 'lisonjeado']\n",
      "Distância entre 'feliz' e 'feiiz': 0.1399279236793518\n",
      "Distância entre 'feliz' e 'triste': 0.14612263441085815\n",
      "Distância entre 'feliz' e 'feiiz': 0.1399279236793518\n",
      "Distância entre 'feliz' e 'contente': 0.15934979915618896\n",
      "Distância entre 'feliz' e 'feiiz': 0.1399279236793518\n",
      "Distância entre 'feliz' e 'aliviada': 0.1600325107574463\n",
      "Distância entre 'feliz' e 'feiiz': 0.1399279236793518\n",
      "Distância entre 'feliz' e 'lisonjeada': 0.1781686544418335\n",
      "Distância entre 'feliz' e 'feiiz': 0.1399279236793518\n",
      "Distância entre 'feliz' e 'excitada': 0.1789391040802002\n",
      "Distância entre 'feliz' e 'feiiz': 0.1399279236793518\n",
      "Distância entre 'feliz' e 'deprimido': 0.18451374769210815\n",
      "Distância entre 'feliz' e 'feiiz': 0.1399279236793518\n",
      "Distância entre 'feliz' e 'agradecida': 0.18496745824813843\n",
      "Distância entre 'feliz' e 'feiiz': 0.1399279236793518\n",
      "Distância entre 'feliz' e 'envergonhada': 0.1854906678199768\n",
      "Distância entre 'feliz' e 'feiiz': 0.1399279236793518\n",
      "Distância entre 'feliz' e 'lisonjeado': 0.19722169637680054\n",
      "Nenhum resultado encontrado que satisfaça a condição.\n"
     ]
    }
   ],
   "source": [
    "# Função para encontrar palavras similares\n",
    "def encontrar_similares(palavra):\n",
    "    try:\n",
    "        similares = model.most_similar(positive=[palavra])      # pega a palavra escolhida\n",
    "        print(f\"Palavras similares a '{palavra}': {[sim[0] for sim in similares]}\")\n",
    "        return [sim[0] for sim in similares]\n",
    "    except KeyError:\n",
    "        print(f\"A palavra '{palavra}' não está no vocabulário.\")        # checa por erros\n",
    "        return []\n",
    "\n",
    "# Função para calcular distância entre palavras\n",
    "def calcular_distancia(palavra1, palavra2):\n",
    "    try:\n",
    "        distancia = model.distance(palavra1, palavra2)      # pega as duas palavras\n",
    "        print(f\"Distância entre '{palavra1}' e '{palavra2}': {distancia}\")\n",
    "        return distancia\n",
    "    except KeyError:\n",
    "        print(f\"Uma das palavras '{palavra1}' ou '{palavra2}' não está no vocabulário.\")        # checa por erros\n",
    "        return float('inf')\n",
    "\n",
    "palavras_teste = [\"manga\", \"maça\", \"feliz\"]     # palavras escolhidas\n",
    "\n",
    "resultado = []\n",
    "\n",
    "# Encontrar sinônimos e antônimos para cada palavra de teste\n",
    "for palavra in palavras_teste:\n",
    "    print(f\"\\nAnalisando a palavra: {palavra}\")\n",
    "    similares = encontrar_similares(palavra)\n",
    "    if similares:\n",
    "        sinonimo = similares[0]\n",
    "        for ant in similares[1:]:\n",
    "            dist_sin = calcular_distancia(palavra, sinonimo)\n",
    "            dist_ant = calcular_distancia(palavra, ant)\n",
    "            if dist_ant < dist_sin:\n",
    "                resultado.append((palavra, sinonimo, ant, dist_sin, dist_ant))\n",
    "\n",
    "# RESULTADOS\n",
    "for res in resultado:\n",
    "    print(f\"\\nPalavra: {res[0]}\")\n",
    "    print(f\"Sinônimo: {res[1]} (Distância: {res[3]})\")\n",
    "    print(f\"Antônimo: {res[2]} (Distância: {res[4]})\")\n",
    "\n",
    "if not resultado:\n",
    "    print(\"Nenhum resultado encontrado que satisfaça a condição.\")      # caso não seja encontrado nenhum resultado final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9Se982Q0P5z"
   },
   "source": [
    "# Analogias\n",
    "\n",
    "Existem algumas analogias famosas realizadas por vetores de palavras. O exemplo mais famoso é provavelmente \"man : king :: woman : x\", onde x é *queen*.\n",
    "\n",
    "Para formular analogias vamos utilizar a função `most_similar()` que busca as palavras mais similares as listas em  `positive` e mais dissimilares as listadas em  `negative`. Para mais detalhes recomendamos consultar a sua [documentação](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "A8zujhY70P5z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('engenheira', 0.7883446216583252),\n",
       " ('investigadora', 0.7415961623191833),\n",
       " ('ex-funcionária', 0.7373332977294922),\n",
       " ('enfermeira', 0.7346670627593994),\n",
       " ('funcionária', 0.7172971367835999),\n",
       " ('bibliotecária', 0.7110162377357483),\n",
       " ('arquiteta', 0.7099220156669617),\n",
       " ('empresária', 0.7055575847625732),\n",
       " ('ex-diretora', 0.7055395841598511),\n",
       " ('professora', 0.697813868522644)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['mulher', 'engenheiro'], negative=['homem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJnuDjo-0P5z"
   },
   "source": [
    "## <font color='blue'>Questão 3 </font>\n",
    "Encontre analogias que funcionam, ou seja, que a palavra esperada está no topo da lista.\n",
    "\n",
    "Descreva sua analogia na seguinte forma: \n",
    "x:y :: a:b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BXpu7g3a0P50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homem : mulher :: rainha : novelo\n",
      "rei : homem :: mulher : esposa\n",
      "paris : frança :: alemanha : berlim\n",
      "alemão : alemanha :: inglaterra : francês\n",
      "brasil : alemanha :: berlim : soweto\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ANALOGIAS PARA TESTE:\n",
    "homem : mulher :: rainha : x\n",
    "rei : homem :: mulher : x\n",
    "paris : frança :: berlim : x\n",
    "alemão : alemanha :: inglês : x\n",
    "Brasil : Alemanha :: Berlim : x\n",
    "'''\n",
    "# Lista com exemplos de analogias\n",
    "analogias = [\n",
    "    ([\"homem\", \"rainha\"], [\"mulher\"]),          # homem : mulher :: rainha : x\n",
    "    ([\"rei\", \"mulher\"], [\"homem\"]),             # rei : homem :: mulher : x\n",
    "    ([\"paris\", \"alemanha\"], [\"frança\"]),        # paris : frança :: berlim : x\n",
    "    ([\"alemão\", \"inglaterra\"], [\"alemanha\"])    # alemão : alemanha :: inglês : x\n",
    "]\n",
    "\n",
    "# Função para encontrar a palavra análoga\n",
    "def encontrar_analogia(positivas, negativas):\n",
    "    try:\n",
    "        similar = model.most_similar(positive=positivas, negative=negativas, topn=1)\n",
    "        return similar[0][0]\n",
    "    except KeyError as e:\n",
    "        print(f\"Palavra não encontrada no vocabulário: {e}\")\n",
    "        return None\n",
    "\n",
    "# Testar cada analogia\n",
    "for pos, neg in analogias:\n",
    "    resultado = encontrar_analogia(pos, neg)\n",
    "    if resultado:\n",
    "        print(f\"{pos[0]} : {neg[0]} :: {pos[1]} : {resultado}\")\n",
    "\n",
    "# mais analogias para teste\n",
    "mais_analogias = [\n",
    "    ([\"brasil\", \"berlim\"], [\"alemanha\"]),       # Brasil : Alemanha :: Berlim : x\n",
    "]\n",
    "\n",
    "for pos, neg in mais_analogias:\n",
    "    resultado = encontrar_analogia(pos, neg)\n",
    "    if resultado:\n",
    "        print(f\"{pos[0]} : {neg[0]} :: {pos[1]} : {resultado}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su8svdBl0P50"
   },
   "source": [
    "## <font color='blue'>Questão 4 </font>\n",
    "Encontre analogias que **Não** funcionam.\n",
    "\n",
    "Descreva o resultado esperado da sua analogia na seguinte forma: \n",
    "x:y :: a:b\n",
    "\n",
    "E indique o valor errado de b encontrado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PdQ2rtyA0P51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homem : mulher :: rainha : rei (Esperado)\n",
      "Valor errado encontrado: novelo\n",
      "\n",
      "rei : homem :: mulher : rainha (Esperado)\n",
      "Valor errado encontrado: esposa\n",
      "\n",
      "alemão : alemanha :: inglaterra : inglês (Esperado)\n",
      "Valor errado encontrado: francês\n",
      "\n",
      "brasil : alemanha :: berlim : brasilia (Esperado)\n",
      "Valor errado encontrado: soweto\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USANDO AS MESMAS ANALOGIAS PARA TESTE, AQUI ESTÃO OS RESULTADOS\n",
    "# Lista de analogias para testar, incluindo o resultado esperado\n",
    "analogias = [\n",
    "    ([\"homem\", \"rainha\"], [\"mulher\"], \"rei\"),      # homem : mulher :: rainha : rei\n",
    "    ([\"rei\", \"mulher\"], [\"homem\"], \"rainha\"),      # rei : homem :: mulher : rainha\n",
    "    ([\"paris\", \"alemanha\"], [\"frança\"], \"berlim\"), # paris : frança :: alemanha : berlim\n",
    "    ([\"alemão\", \"inglaterra\"], [\"alemanha\"], \"inglês\") # alemão : alemanha :: inglaterra : inglês\n",
    "]\n",
    "\n",
    "# Função para encontrar a palavra análoga\n",
    "def encontrar_analogia(positivas, negativas):\n",
    "    try:\n",
    "        similar = model.most_similar(positive=positivas, negative=negativas, topn=1)\n",
    "        return similar[0][0]\n",
    "    except KeyError as e:\n",
    "        print(f\"Palavra não encontrada no vocabulário: {e}\")\n",
    "        return None\n",
    "\n",
    "# Testar cada analogia\n",
    "for pos, neg, esperado in analogias:\n",
    "    resultado = encontrar_analogia(pos, neg)\n",
    "    if resultado and resultado != esperado:\n",
    "        print(f\"{pos[0]} : {neg[0]} :: {pos[1]} : {esperado} (Esperado)\")\n",
    "        print(f\"Valor errado encontrado: {resultado}\\n\")\n",
    "\n",
    "# Adicionar suas próprias analogias para testar\n",
    "# exemplo: analogia customizada com resultado esperado\n",
    "custom_analogias = [\n",
    "    ([\"brasil\", \"berlim\"], [\"alemanha\"], \"brasilia\"), # Brasil : Alemanha :: Berlim : Brasilia\n",
    "]\n",
    "\n",
    "for pos, neg, esperado in custom_analogias:\n",
    "    resultado = encontrar_analogia(pos, neg)\n",
    "    if resultado and resultado != esperado:\n",
    "        print(f\"{pos[0]} : {neg[0]} :: {pos[1]} : {esperado} (Esperado)\")\n",
    "        print(f\"Valor errado encontrado: {resultado}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8LYWJ1i0P51"
   },
   "source": [
    "# Viés e preconceito adquirido\n",
    "\n",
    "Como estes vetores são aprendidos a partir de documentos produzidos pela nossa sociedade, ele pode vir a capturar alguns preconceitos e desigualdades presentes na nossa sociedade. É importante estar ciente desse viés de nossos vetores e dos seus perigos, aplicações que utilizam esses modelos podem acabar perpetuando e até mesmo exacerbando desigualdades sociais.\n",
    "\n",
    "Por exemplo, uma analogia problemática capturada:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "53KYiqsc0P51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('branco', 0.663209080696106),\n",
       " ('alegre/rs', 0.6620162725448608),\n",
       " ('braga-fc', 0.6464027762413025),\n",
       " ('sporting-fc', 0.6254758238792419),\n",
       " ('côvo', 0.6254613995552063),\n",
       " ('alegre-rs', 0.6199708580970764),\n",
       " ('vermelho', 0.612277090549469),\n",
       " ('covo', 0.604120671749115),\n",
       " ('cirílicos', 0.6022458672523499),\n",
       " ('benfica-fc', 0.5965930819511414)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['negro', 'rico'], negative=['pobre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BS-sruEp0P52"
   },
   "source": [
    "Note também como diferem as palavras mais semelhantes a homem e mulher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bgtl4cgN0P53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monstro', 0.9085395932197571),\n",
       " ('bebé', 0.9072304368019104),\n",
       " ('indivíduo', 0.9050756096839905),\n",
       " ('rapaz', 0.9036115407943726),\n",
       " ('mendigo', 0.9007540345191956),\n",
       " ('rapazola', 0.8992964029312134),\n",
       " ('novelo', 0.8938027620315552),\n",
       " ('pássaro', 0.8897998929023743),\n",
       " ('cão', 0.8882535099983215),\n",
       " ('cãozinho', 0.8869855403900146)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"homem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bExfFYGS0P53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('menina', 0.911119282245636),\n",
       " ('amiga', 0.9089193344116211),\n",
       " ('cadela', 0.9035040140151978),\n",
       " ('rapariga', 0.899989902973175),\n",
       " ('enfermeira', 0.8974366784095764),\n",
       " ('namorada', 0.8954240083694458),\n",
       " ('cafetina', 0.8932163119316101),\n",
       " ('prostituta', 0.8917951583862305),\n",
       " ('garota', 0.8906298279762268),\n",
       " ('cadelinha', 0.8902611136436462)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"mulher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgNf_9-P0P53"
   },
   "source": [
    "## <font color='blue'>Questão 5 </font>\n",
    "\n",
    "Utiliza a função `most_similar()` para encontrar um outro caso de viés adquirido pelos vetores e explique brevemente o tipo de viés encontrado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "FuHqTKSB0P53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('menino', 0.888033390045166), ('casal', 0.8774283528327942), ('taxista', 0.8716806173324585), ('carcereiro', 0.8708066940307617), ('rapaz', 0.8702239990234375), ('reeducando', 0.8644770979881287), ('fazendeiro', 0.8624474406242371), ('caminhoneiro', 0.8587703108787537), ('porteiro', 0.8562619686126709), ('faroleiro', 0.8533437848091125)]\n"
     ]
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "vies = model.most_similar(\"idoso\")\n",
    "print(vies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TID_Rbk70P53"
   },
   "source": [
    "\n",
    "**<font color='green'>Resposta:</font>**\n",
    "\n",
    "No código acima, foi utilizada a palavra \"idoso\" para tentar extrair algum viés adquirido pelos vetores, seja positivo ou negativo, e pelas respostas, concluimos que o vetor tende a pensar que certas profissões são relacionadas a palavra \"idoso\", profissões como: taxista, carcereiro, fazendeiro, caminhoneiro, porteiro e faroleiro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5ih_CvL0P53"
   },
   "source": [
    "## <font color='blue'>Questão 6 </font>\n",
    "\n",
    "Qual é a possivel origem desses vieses? Tente explicar como eles podem ter sido capturados pelos vetores de palavras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nm8ty0WH0P54"
   },
   "source": [
    "\n",
    "**<font color='green'>Resposta:</font>**\n",
    "\n",
    "Os vieses em modelos de vetores surgem, basicamente, dos dados de treinamento que refletem preconceitos sociais. Por exemplo, associações como \"mulher\" com \"dona-de-casa\" e \"negro\" com \"pobre\" são aprendidas a partir de textos que provavelmente reforçam estes estereótipos. Esses modelos capturam padrões linguísticos que refletem desigualdades, influenciando como palavras são relacionadas nos resultados. Logo, o modelo apenas está aprendendo o que está sendo passado para ele.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Lista 04 - Word2Vec.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/alan-barzilay/NLPortugues/blob/master/Semana%2004/Lista%2004%20-%20Word2Vec.ipynb",
     "timestamp": 1652789395000
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
